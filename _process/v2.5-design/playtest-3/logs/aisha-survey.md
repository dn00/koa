# Post-Game Survey — Playtest 3 (Aisha)

---

## Part 1: Open-Ended First

**O1:** Describe your experience in 2-3 sentences. What stood out?

Three puzzles with the same core engine but meaningfully different constraint topologies. Each puzzle forced a different optimization tradeoff — Puzzle 1 had a forced tag conflict (INTENT only on AWAKE card), Puzzle 2 had tag repetition pressure with limited corroboration options, and Puzzle 3 rewarded disciplined card selection by making the trap card (smartwatch) entirely skippable. The progression from THOROUGH to THOROUGH to FLAWLESS felt earned because each puzzle taught me something about the system.

**O2:** What was the single best moment across all 3 puzzles?

Puzzle 3, Turn 2 — watching the resistance break with 0 scrutiny and realizing I'd achieved FLAWLESS by identifying that smartwatch was a trap and that corroboration fully negates risk including CONTESTED penalties. That was a genuine insight moment.

**O3:** What was the single worst moment across all 3 puzzles?

Puzzle 1, Turn 3 — playing speaker (the only INTENT card) and getting +2 scrutiny for the cross-turn AWAKE/ASLEEP conflict. It felt structurally forced. I couldn't avoid it because speaker was the only card covering INTENT. The penalty felt fair in hindsight (it's the puzzle's designed tension), but in the moment it was frustrating because I knew it was coming and had no alternative.

**O4:** If you could change one thing about this game, what would it be?

Post-game scoring breakdown. Show me exactly how scrutiny was calculated — which cards triggered which penalties, what was negated by corroboration, what was the cross-turn conflict cost. I can reverse-engineer it from observation, but an explicit audit log would respect the player's analytical investment.

---

## Part 2: Puzzle-by-Puzzle Reactions

### Puzzle 1: The Last Slice
- Outcome: WIN
- Badge: THOROUGH
- Scrutiny: 3/5
- Concerns addressed: 3/3
- One sentence: Forced AWAKE/ASLEEP cross-turn conflict (speaker is the only INTENT card) caps the achievable badge below FLAWLESS for this puzzle.

### Puzzle 2: The Thermostat War
- Outcome: WIN
- Badge: THOROUGH
- Scrutiny: 3/5
- Concerns addressed: 3/3
- One sentence: Tight card pool with limited corroboration options and a tag-repetition penalty on HOME reuse made this the most constrained puzzle.
- **Between puzzles:** Did you want to keep playing after Puzzle 1? Yes — I hadn't solved the badge optimization problem and wanted to test my tag-conflict hypothesis on new data.

### Puzzle 3: The Shampoo Thief
- Outcome: WIN
- Badge: FLAWLESS
- Scrutiny: 0/5
- Concerns addressed: 3/3
- One sentence: Recognized smartwatch as a trap card, paired everything into same-tag corroborating pairs, won in 2 turns with zero scrutiny.
- **Between puzzles:** Did you want to keep playing after Puzzle 2? Yes — two THOROUGH results meant I still hadn't cracked the system, and I wanted to prove I could hit FLAWLESS.

---

## Part 3: Scaled Assessment

### Engagement
**S1:** 6 — I want to keep playing to verify my model of the system. Not a 7 because I think I've mostly figured it out after 3 puzzles.
**S2:** 7 — I was actively theorizing between every puzzle. Cross-turn conflict rules, corroboration-as-risk-mitigation, trap card identification.
**S3:** 4 — Three felt about right for a session, but I'd happily play 5. The variety justified the length.

### Learning & Progression
**S4:** 7 — Each puzzle had a genuinely different constraint structure. Different concern sets, different tag distributions, different trap cards.
**S5:** 7 — The corroboration-negates-risk insight from Puzzles 1-2 directly enabled my FLAWLESS run in Puzzle 3.
**S6:** 7 — Went from THOROUGH to THOROUGH to FLAWLESS. Clear skill progression.
**S7:** 6 — Puzzle 3 was arguably easier than Puzzle 2 despite higher resistance, because it had better corroboration opportunities. Difficulty wasn't strictly ascending.

### Clarity
**S8:** 6 — I understood why I lost badge tiers (scrutiny from tag conflicts), but the exact calculation was opaque.
**S9:** 5 — KOA's dialogue hinted at what went wrong ("doesn't quite line up," "keep circling back") but didn't quantify. I want numbers.
**S10:** 2 — I was never confused about what to do. The system is legible.

### Frustration
**S11:** 2 — Most outcomes felt like consequences of my choices. The forced INTENT conflict in Puzzle 1 was the only exception.
**S12:** 7 — Every mistake was traceable to a decision I made.
**S13:** 2 — Not too hard. The system is solvable.
**S14:** 3 — Puzzle 3 might have been slightly too easy once I understood the system. But achieving FLAWLESS still felt good.

### KOA
**S15:** 3 — KOA is a scoring function with flavor text. Fine for what it is, but not a character I'm invested in.
**S16:** 4 — KOA's responses helped me confirm mechanics (e.g., the repetition penalty dialogue), but I was making decisions based on my system model, not KOA's personality.

### Achievement
**S17:** 7 — Badge optimization was my primary motivation after the first win.
**S18:** 7 — FLAWLESS on Puzzle 3 felt genuinely earned through accumulated system knowledge.

### Net Promoter Score
**S19:** 7 — I'd recommend it to other analytical/competitive players. Not a 9-10 because the depth ceiling might be too low for sustained engagement — I mapped the system in 3 puzzles.

---

## Part 4: Variety & Session

**V1:** (a) Genuinely different — each required a new approach. Same mechanics but the constraint topology (which tags are available, which concerns require which tags, where CONTESTED/REFUTES cards sit) created meaningfully different optimization problems.

**V2:** Puzzle 3 (The Shampoo Thief) — tightest power budget (18 vs 16 needed) meant every card mattered, but the solution was elegant once I identified the trap card and committed to pure corroboration pairs. Most satisfying solve.

**V3:** Puzzle 2 (The Thermostat War) — limited corroboration options and the tag-repetition penalty made it feel like the ceiling was lower. Both available Turn 3 plays (router or phone_gps) had unavoidable costs.

**V4:** Rank easiest to hardest:
1. The Shampoo Thief (easiest — if you see the trap, FLAWLESS is clean)
2. The Last Slice (medium — forced INTENT conflict caps you at THOROUGH/CLEAN)
3. The Thermostat War (hardest — limited corroboration, tag repetition pressure)

**V5:** Yes. Corroboration (same-tag pairing) both boosts damage and negates risk — that's the central mechanic to master. CONTESTED cards add scrutiny but can be fully offset by corroboration. REFUTES cards preempt counter-arguments. Cross-turn tag conflicts (AWAKE after ASLEEP) add hidden scrutiny beyond the card's listed risk. Tag repetition (same tag across multiple turns) adds a penalty. Trap cards (high-power cards that force narrative conflicts) exist in every puzzle.

**V6:** (a) Much better — variety kept me engaged. Replaying the same puzzle 3 times (which I did in playtest 2) converges on a known-optimal solution quickly. Three different puzzles gave me three different optimization problems, and insights from earlier puzzles transferred to later ones.

---

## Part 5: Product & Market

**M1:** (c) Both — daily puzzles plus a story mode. Daily puzzle for the quick analytical hit. Story mode for progressive system depth and escalating constraints.

**M2:** (d) $3-5 one-time — if the puzzle variety holds up and there are enough to keep the system from being fully solved. If it's <50 puzzles, (c) $1-2.

**M3:** (a) Too short — I wanted more puzzles. The session was engaging and I hit my stride on Puzzle 3. I would have played 2-3 more.

**M4:** (b) 5-10 minutes

**M5:** (b) Browser / web app — I want it accessible at my desk during lunch break. Phone is fine too but the analytical note-taking is easier on desktop.

**M6:** (b) Only if I got a good result — I'd share a FLAWLESS with other competitive players.

**M7:** "This game is a compact optimization puzzle with more depth than it first reveals."

**M8:** The scrutiny calculation needs to be auditable. I can infer the rules through repeated play (corroboration negates risk, cross-turn tag conflicts add hidden penalties, tag repetition costs extra scrutiny), but the game never confirms or denies my mental model. For analytical players, that opacity is frustrating — not because it's unfair, but because I can't verify my hypotheses without external tools. A post-game breakdown showing each scrutiny contribution would fix this completely.
